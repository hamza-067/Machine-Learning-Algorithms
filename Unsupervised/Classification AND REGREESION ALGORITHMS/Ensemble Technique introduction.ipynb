{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d39fa1c2-06f8-47c9-b231-53cdec335385",
   "metadata": {},
   "source": [
    "Ensemble techniques in machine learning combine multiple models to improve predictive performance, making models more accurate and robust by reducing bias and variance. The most common ensemble methods include bagging, which reduces variance, and boosting, which reduces bias by training models sequentially. Stacking is another method that combines the outputs of several models using another model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456651a0-ef49-433d-b73c-9d3535f6a6dc",
   "metadata": {},
   "source": [
    "# Bagging (Bootstrap Aggregating) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a6dec-97a4-4299-8981-5a85db475c07",
   "metadata": {},
   "source": [
    "It involves creating multiple subsets of the original training data by sampling with replacement (bootstrapping). \n",
    "    \n",
    "Multiple base models are trained on these different subsets. \n",
    "    \n",
    "Predictions are combined, often through a majority vote for classification or averaging for regression, to produce the final output. \n",
    "    \n",
    "A classic example is a {Random Forest}, which uses bagging with decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f1d204-6d9e-479d-9705-d4fd882c3357",
   "metadata": {},
   "source": [
    "# Boosting:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eb8f3d-e944-49a8-9192-1bbbbc6624aa",
   "metadata": {},
   "source": [
    "This is a sequential technique that reduces bias. \n",
    "\n",
    "Models are built one after another, with each new model focusing on correcting the errors of the previous ones.\n",
    "\n",
    "It works by assigning higher weights to the data points that were misclassified by earlier models. \n",
    "\n",
    "Examples include {AdaBoost} and {Gradient Boosting (like XGBoost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab4f5cd-6133-4f81-87fa-d91cb816a640",
   "metadata": {},
   "source": [
    "# Stacking:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdba516-d7a8-4547-909f-ac1fb7620981",
   "metadata": {},
   "source": [
    " This method combines the predictions of multiple different base models to make a final prediction. \n",
    "     \n",
    "A meta-model (or \"level-one\" model) is trained on the outputs of the base models (the \"level-zero\" models). \n",
    "\n",
    "The goal is to find the best way to combine the base models' predictions, which can often lead to better performance than any single base model alone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4535a36c-c5a5-43cd-8d9d-cc227d6b80a3",
   "metadata": {},
   "source": [
    "# Basic Ensemble Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a4501b-ad62-4030-a8d4-e99a6d139d35",
   "metadata": {},
   "source": [
    "1. Max Voting\n",
    "\n",
    "2. Averaging\n",
    "\n",
    "3. Weighted Average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b60419-1846-498b-b7c8-5d1a6f8025d9",
   "metadata": {},
   "source": [
    "# Advanced Ensemble Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2d3ce-3ca7-48f3-a5ad-5f0dac3173b6",
   "metadata": {},
   "source": [
    "1. Stacking\n",
    "\n",
    "2. Blending\n",
    "\n",
    "3. Bagging\n",
    "\n",
    "4. Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807a3c30-7b8c-41c1-802e-69ca1de55dfe",
   "metadata": {},
   "source": [
    "# Algorithms Based On Bagging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1213f1-e66f-4ee5-b6e5-0732265d430e",
   "metadata": {},
   "source": [
    "1. Bagging meta-estimator\n",
    "\n",
    "2. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f78e01-9c06-449d-af61-539f682b3230",
   "metadata": {},
   "source": [
    "# Algorithms Based On Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cedd28e-40d7-4dc1-9228-1de7b41e4c55",
   "metadata": {},
   "source": [
    "1. AdaBoost\n",
    "\n",
    "2. GBM\n",
    "\n",
    "3. XGBM\n",
    "\n",
    "4. Light GBM\n",
    "\n",
    "5. Cat Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcedf81-4d1b-4eb1-a7d5-1f2155b28cda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
